---
title: "Day 9 Lecture"
output: html_document
---

# Today's agenda
  - More on loops
  - More on functions
  - Vectorization
  
```{r}
#Today's packages
library(MASS)
library(tidyverse)
library(reshape2)
```
  

# Loops

## Using a loop for a repetitive task

```{r}
scottdata <- read.csv(file.choose())
head(scottdata)
colnames(scottdata)

# standardize every "entropy" column using scale()
# scale is used to standardized. sometimes gives you a named vector, so scott is in the habit of making it numeric. mean 0, sd 1. if you do scale = false, then centers but doesn't scale. 

# without a loop - this is how you'd do it by hand.
# scottdata$AllEntropy <- as.numeric(scale(scottdata$AllEntropy))
# scottdata$WithinEntropy <- as.numeric(scale(scottdata$WithinEntropy))
# scottdata$SegEntropy <- as.numeric(scale(scottdata$SegEntropy))
# scottdata$BiphoneEntropy <- as.numeric(scale(scottdata$AllEntropy))

# with a loop
entropy.columns <- c("AllEntropy", "WithinEntropy", "SegEntropy", "BiphoneEntropy") #first defining what your new column names would be.

for(column.name in entropy.columns) {
  scottdata[, column.name] <- as.numeric(scale(scottdata[, column.name]))
}



summary(scottdata[, entropy.columns])
sapply(scottdata[, entropy.columns], sd)  #applies a function (sd) for each thing in the columns

```

## Using a loop with a list as a "results container"

```{r}
# use a loop to get several regression results, one for each species
my.iris <- iris

# "by hand", without a loop. subsetting the data so you're just getting one species
lm.setosa <- lm(Sepal.Width ~ Sepal.Length, data = my.iris[my.iris$Species == "setosa", ])
lm.versicolor <- lm(Sepal.Width ~ Sepal.Length, data = my.iris[my.iris$Species == "versicolor", ])
lm.virginica <- lm(Sepal.Width ~ Sepal.Length, data = my.iris[my.iris$Species == "virginica", ])

# with a loop
all.species <- unique(as.character(my.iris$Species))   #just making a vector of the levels. this is what we'll loop over.
# all.species <- "some other value" # alternative

# set up container to "store" results. before you do the loop, where are you going to put the results??
# making a list where each member of the list is going to be the regression results
byspecies.results <- list()
length(byspecies.results) <- length(all.species)     #want the 'container' to be the right size before start
names(byspecies.results) <- all.species

# loop over species names
for(this.species in all.species) {
  # run the analysis, plug the results into the "results container"
  # double bracket - 'the value in this member of the list'
  byspecies.results[[this.species]] <- lm(Sepal.Width ~ Sepal.Length, data = my.iris[my.iris$Species == this.species, ])
}

length(byspecies.results)
class(byspecies.results[1]) # of the list
class(byspecies.results[[1]]) # of the thing within the list
summary(byspecies.results[[1]])
lapply(byspecies.results, summary) #lapply() does something to a list and returns a list


# question about plots etc. how to add sonmething to the list?

pdf("plots of regressions2.pdf")

for(this.species in all.species) {
  this.data = my.iris[my.iris$Species == this.species, ] #moving the subsetting up to a different line
  byspecies.results[[this.species]] <- lm(Sepal.Width ~ Sepal.Length, data = this.data) #took the subset out of here
  
  print(ggplot(this.data, aes(Sepal.Length, Sepal.Width)) + geom_point() + geom_smooth(method = "lm") + ggtitle(this.species)) #remember you have to tell it to print. and if you want to do pdf then you have to create the pdf first (see above loop)
}

dev.off() #stops the pdf


#if you want to save as something else, could do PNG (for word docs)

png("iris regression.png", height = 2, width = 4, units = "in", res = 300) #prefers to specify the dimensions of the plot and the resolution

ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_point() + geom_smooth(method = "lm") + 
ggtitle("iris regression")

dev.off() #stops the png

#messing with the scales for facet_wrap
ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_point() + geom_smooth(method = "lm") + ggtitle("iris regression") + facet_wrap(~Species, scales = "free_x")

```


# Some other notes on loops

## Different kinds of "counters" possible

```{r}
for(counter in list(iris$Sepal.Length, iris$Sepal.Width, iris$Petal.Length, iris$Petal.Width)) {
#  print(counter)
  print(length(counter))
  print(mean(counter))
}

for(column.name in colnames(iris)[1:4]) {
  print(mean(iris[, column.name]))
}

for(counter in 1:1000) { # pretend that counter == 843 is bad, we want to skip it
  if(counter %in% c(843)) {
    
  } else {
    # whole code block here 
  }
}

```

## "Debugging" tips for for-loops

  - if you get an error, the counter variable is at the value when things broke
  - insert `print()` statements to check on things mid-loop
  - manually set the counter variable value, step through the loop
  
```{r}
#this is a dumb example, a quick way to show how you'd fix something that breaks differently each time.
log(rnorm(10,3,1))

values = rnorm(1e6, 3, 1)

#creating results container
my.results = vector()
length(my.results) = length(values)

#going one by one through the values to get the log of each value. dumb way to do this
for (this.value in 1:length(values)) {
  my.results[this.value] = log(values[this.value])
}

summary(my.results) #lots of warnings with NAs! why?

#how to troubleshoot? adding an if statement

for (this.value in 1:length(values)) {
  my.results[this.value] = log(values[this.value])
  if(is.na(my.results[this.value])) { break }
}

this.value #retrieves which one you're on
values [1330] #retrieves what the value was. it's negative! can't take log of a negative
```
  
  

===========
# Functions
===========
  - making a function
  - anonymous functions
  - environments
  - making functions available
  - debugging

## Review function basics
  - basic syntax very simple!

```{r eval = FALSE}
my.function <- function(arg1, arg2, ...) {
  #FUNCTION BODY  
  return(the.value.you.want.returned)
  #last value in function body is default for return()
}

#basic function, you create an object, use function function, then you define all the arguments. 
#can think about it as how it should/would look in the help file. 
#then your function body. can put in explicit return() or not


#relationship between functions and loops.
# a loop can easily modify other variables from the workspace
# a FUNCTION creates its own miniature world that insulated from the rest of the code.
# first place the function looks for things is in its arguments.

```

## Transitioning from a loop to a function

```{r}

# with a loop
all.species <- unique(as.character(my.iris$Species)) 

# set up container to "store" results
byspecies.results <- list()
length(byspecies.results) <- length(all.species)
names(byspecies.results) <- all.species

# loop over species names
for(this.species in all.species) {
 this.data <- my.iris[my.iris$Species == this.species, ]
 byspecies.results[[this.species]] <- 
   lm(Sepal.Width ~ Sepal.Length, data = this.data)
}

names(byspecies.results)
str(byspecies.results)

#above, made a loop to do some stuff

#creates a function. deciding what is going in/out of that function
run.my.regression = function(species, data = iris) {
  species.data = data[data$Species == species, ]       #when it gets to this line of code, function looks for                                                         data, and first looks in it's own arguments. we                                                               defined data above.
                                                        #subsetting by the species argument
  output = lm(Sepal.Width ~ Sepal.Length, data = data) #saves an output object
  output
}

result1 = run.my.regression(species = "setosa")
summary(result1)

result2 = run.my.regression(species = "virginica")
summary(result2)

# now we have a made a kind of dumb limited use case function. assumes a species column and certain data columns

#make more general by adding arguments to the function
run.my.regression = function(species, regression.formula, data = iris) {
  species.data = data[data$Species == species, ]      
  output = lm(regression.formula, data = data) 
  output
}

result3 = run.my.regression(species = "virginica", regression.formula = Sepal.Length~Sepal.Width, data = iris)
summary(result3)

```


```{r}
#question about changing things in the global workspace. possible but don't do it.

x = 1:10

doublelog = function(x) {
  x = 2*log(x)
  return(x)
}

y = doublelog(x)
y

evil.doublelog = function(x) {
  x <<- 2*log(x)              ## <<- changes a thing in the global environment
  return(x)
}

  
```


# Vectorization overview
  - sometimes faster (not always)
  - sometimes easier to think about (not always)
  - split-apply-combine
  - "anonymous" functions = "one-use" functions

```{r}
x <- 1:10

x * 3 # "true" vectorization, multiplies each thing in the vector

x <- 1:1e6
system.time(y <- x * 3) #tells you how long something took to run (and runs it)

y2 <- vector(length = length(x))   #stepping through our million long x and putting results in y2, can see                                        that it's slower
system.time(for(i in x) {
  y2[i] <- x[i] * 3
})

```

# The `apply` family and "anonymous" functions

### `sapply`
  - "simple" apply
  - returns a vector
  - good for just applying a function to each thing in a vector

```{r}
#this is base R
#s stands for simple. gives you back a vector

head(iris)
#say we want SD for each of the columns
#sapply works for anything that has a length dimension, great to run over every member of a thing

length(iris[, 1:4])
sapply(iris[, 1:4], FUN = sd)


# anonymous functions
#what if I wanted to get a quick standard error for each of these?
# could define function separately

std.err = function(x) {
  sd(x)/sqrt(length(x))
}

sapply(iris[, 1:4], std.err)

#what if I didn't want to do all the seaprate steps, but do it at once?

sapply(iris[, 1:4], function(x) sd(x)/sqrt(length(x))) #works as a short one-off function definition
#for every member of the thing, it gets passed to the 'anonymous' function (doesn't get a name). 

```


## `apply`

- good for "row-wise" operations over data frames (or column-wise)
- give it only the columns/rows you want to operate on
- the `MARGIN` argument says whether it's row-wise (=1) or column-wise (=2)
- the `FUN` argument says what to do with each row/column-wise vector

```{r}

#what if we wanted to do something with more than one column at a time
myris = iris

head(myris)
#want a column that's the average of each of the 4 columns, or something

myris$petal.sum = myris$Petal.Length+myris$Petal.Width #could do this
head(myris)

myris$avg = mean(myris$Petal.Length:myris$Petal.Width) #doesn't do what you'd think!
head(myris)


#here's what to do
myris$allmean = apply(myris[, 1:4], MARGIN = 1, mean) #MARGIN 1 means row wise
head(myris)


apply(myris[, 1:4], MARGIN = 2, mean) #MARGIN 2 gets you column means


#DPLYR way? we'll get to that later


```

## other members of the `apply` family
  - generally avoid, if possible!

### `lapply`
  - "list" apply
  - does something to each member of a list/vector
  - returns a list

### `tapply`
  - "table" apply
  - does something to data in "cells" by a combination of factors
  - returns a table


# More general solutions: `plyr` and `dplyr`
  - best for data frames
  
## `plyr`
  - the `plyr` package is older, slower, not under very active development
  - instantiates a "split-apply-combine" philosophy
  - handy paper here: http://www.jstatsoft.org/v40/i01
  - series of related functions
    - XYply, where X = "thing you give it" and Y = "thing it gives you back"
    - `ldply()` = you give it a list, it gives you back a data frame
    - `daply()` = you give it a data frame, it gives you back an array
    - etc.

## `dplyr`
  - the most common usage for `plyr` is `ddply()` -- give it a data frame and get a data frame back
  - the `dplyr` package takes this and runs with it
  - DON'T library both packages in the same session (unless you really need to and know what you're doing)
  - `dplyr` is implemented to be much faster
  - `dplyr` has rapidly taken over from `plyr`
  
### `dplyr` usage
  
  - "verbs": `mutate`, `filter`, `select`, `summarise` (or `summarize`), `arrange`
  - use `group_by()` to set the groups over which something (like `summarize` will apply)
  - `mutate` = "transform"
  - `filter` = "get some of the rows"
  - `select` = "get some of the columns"
  - `summarize` = boil things down to some kind of summary
  - `do` = general purpose!

### reviewing `summarize()`

```{r}
mysleep <- sleep
mysleep.means <- group_by(mysleep, group) %>% summarize(mean = mean(extra), sd = sd(extra), se = std.err(extra))
mysleep.means
summarize(mysleep, mean = mean(extra), sd = sd(extra))  #saves you a step

```

### `mutate()` and `rowwise()`

```{r}

myris = iris
myris$mean = apply(iris[, 1:4], 1, mean)
head(myris)

#can use mutate in the same way
#if you want the rowwise mean, you need to use row wise

myris = mutate(myris, mean2 = mean(c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width))) #still does the wrong thing.
head(myris)

myris = rowwise(myris) %>% mutate(mean2 = mean(c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width))) 
head(myris)
#rowwise is a special case of group by



mysleep$new <- mysleep$extra * 3
head(mysleep)
double.max(mysleep.wide$pre)

mysleep.wide <- mutate(mysleep.wide, newcol3 = double.max(c(pre, post)))
head(mysleep.wide)

mysleep.wide <- 
  rowwise(mysleep.wide) %>%
  mutate(newcol3 = double.max(c(pre, post))) # or newcol3 = max(pre, post) * 2
mysleep.wide

# dplyr with reshaping
mysleep.wide %>%
  gather(condition, extra.sleep, pre:post) %>%
  group_by(ID) %>%
  mutate(newcol4 = double.max(extra.sleep)) %>%
  spread(condition, extra.sleep)

```

### example of `do()` vs. a loop
  
```{r}
# using the iris data, write code to:
# - run a t.test, and 
# - pull out the t, df, and p-value into a (one-row) data frame
my.iris <- iris
ttest.results <- t.test(my.iris[, "Sepal.Length"], my.iris[, "Sepal.Width"])
t.val <- ttest.results$statistic
df.val <- ttest.results$parameter
p.val <- ttest.results$p.value

results.table <- data.frame(t = t.val,
                            df = df.val,
                            p.val = p.val)
results.table

# write the code to do the same thing, once for "setosa" and once for "versicolor"
ttest.results <- 
  t.test(my.iris[my.iris$Species == "setosa", "Sepal.Length"], 
         my.iris[my.iris$Species == "setosa", "Sepal.Width"])
t.val <- ttest.results$statistic
df.val <- ttest.results$parameter
p.val <- ttest.results$p.value

results.table <- data.frame(t = t.val,
                            df = df.val,
                            p.val = p.val)
results.table

# write a loop to go through all levels of Species
# 1. copy & paste 1-time code
# 2. find the place(s) where the code needs to vary in each loop
# 3. replace those varying places with a counter
# 4. set up the counter to iterate through the values you want
# 5. you may need to set up a results "container" where each loop will
#    add something
# 6. double-check stuff

all.species.names <- levels(my.iris$Species)          #setting up our blank results table
results.table <- data.frame(Species = all.species.names,
                            t = NA,
                            df = NA,
                            p.val = NA)
results.table
for(species.name in all.species.names) {
  ttest.results <- 
    t.test(my.iris[my.iris$Species == species.name, "Sepal.Length"], 
           my.iris[my.iris$Species == species.name, "Sepal.Width"])
  t.val <- ttest.results$statistic
  df.val <- ttest.results$parameter
  p.val <- ttest.results$p.value

  results.table[results.table$Species == species.name, #matching the value of the table for the current loop
                c("t", "df", "p.val")] <- c(t.val, df.val, p.val)
}
results.table

# write a function that will return the one-row data frame of results  
# making this benefit us by letting control which things we are testing - more general function
# also this is a case where tibble messes you up. with a dataframe, you get a vector, but a single column of a tibble is still a dataframe
get.ttest <- function(data, col1, col2) {
  # data is a data frame
  # col1 is a string that's a column name
  # col2 is a string that's another column name
  data <- as.data.frame(data)
  ttest.results <- t.test(data[, col1], data[, col2]) # generalized for which columns
  t.val <- ttest.results$statistic
  df.val <- ttest.results$parameter
  p.val <- ttest.results$p.value
  
  results.table <- data.frame(t = t.val,
                              df = df.val,
                              p.val = p.val)
  results.table
}
# run the function on the overall iris data

get.ttest(data = my.iris, col1 = "Sepal.Width", col2 = "Sepal.Length")  #NOW you run the function

# use group_by() and do() to get the results separately for each level of Species - run the function for any combination of factors we want. here comes the final payoff!

my.byspecies.results <- group_by(my.iris, Species) %>%  #group by species and say do()
  do(get.ttest(., col1 = "Sepal.Width", col2 = "Sepal.Length")) 

#inside do, '.' means the dataframe I just got with the grouping

my.byspecies.results

myris = as.data.frame(iris)
myris$plantID = 1:nrow(myris)
head(myris)
myris.long = gather(myris, part.dim, cm, Sepal.Length:Petal.Width)
head(myris.long)
myris.long = separate(myris.long, part.dim, into = c("part", "dim"), sep = "\\.")
head(myris.long)


myris.wide = spread(myris.long, dim, cm)
head(myris.wide)

#got to this point because we want to test the means between length and width
get.ttest(myris.wide, "Length", "Width")

#what if we want to split this by species???
group_by(myris.wide, Species) %>% do(get.ttest(., "Length", "Width"))

group_by(myris.wide, Species, part) %>% do(get.ttest(., "Length", "Width"))

#this is the payoff for creating a function! Remember? We created get.ttest()

debug(get.ttest)
# undebug(get.ttest)

#debug - can do this for any function
#now, when you run the function, it puts you in 'debugging mode'
#steps through your code line by line and shows you what's in your environment
#can enter things at any point in the browse line to see what the status is, like objects(), etc
#can also put 'browser()' at any point in your function and it'll pop you into browser/debug mode at that point if you don't want to have to step through the whole thing.


group_by(my.iris, Species) %>%
  do(get.ttest(., col1 = "Petal.Width", col2 = "Petal.Length")) 

head(minpair)

group_by(minpair, Corpus) %>%
  do(get.ttest(., col1 = "WithinMinPairs", col2 = "BetweenMinPairs"))

```

# Retrospective construction of the function

```{r eval = FALSE}
# start with the results I want
my.ttest.results <- data.frame(mean1 = this.mean1, mean2 = this.mean2, t = this.t, df = this.df, p = this.pval)

# how do I get those?
this.mean1 <- this.ttest$estimate[1]
this.mean2 <- this.ttest$estimate[2]
this.t <- this.ttest$statistic
this.df <- this.ttest$parameter
this.pval <- this.ttest$p.value

# where do I get the t-test?
this.ttest <- t.test(data[[var1]], data[[var2]])

# example: get it to run ONCE
this.ttest <- t.test(mydata$conditionA, mydata$conditionB)
this.mean1 <- this.ttest$estimate[1]
this.mean2 <- this.ttest$estimate[2]
this.t <- this.ttest$statistic
this.df <- this.ttest$parameter
this.pval <- this.ttest$p.value
my.ttest.results <- data.frame(mean1 = this.mean1, mean2 = this.mean2, t = this.t, df = this.df, p = this.pval)

my.ttest.results

# functionizing: make things abstract, pull out constants
# new.function <- function(v1, v2) {
# 
# ...

# new.function <- function(data) {
#  this.ttest <- t.test(data$conditionA, data$conditionB)
  
final.version <- function(data, vars) {
  this.ttest <- t.test(data[[vars[1]]], data[[vars[2]]])
  
```


# More examples

```{r}
myris <- iris
myris$plantID <- 1:nrow(myris)
myris <- gather(myris, myvariable, cm, 1:4)
myris <- separate(myris, myvariable, c("part", "dimension"), sep = "\\.")
myris$part <- as.factor(myris$part)
myris$dimension <- as.factor(myris$dimension)

head(myris)

# how many times now have we done this?
# why not make this a function?
clean.iris <- function(iris = iris) {
  library(tidyr)
  myris <- iris
  myris$plantID <- 1:nrow(myris)
  myris <- gather(myris, myvariable, cm, 1:4)
  myris <- separate(myris, myvariable, c("part", "dimension"), sep = "\\.")
  myris$part <- as.factor(myris$part)
  myris$dimension <- as.factor(myris$dimension)
  myris
}

myris2 <- clean.iris(iris)
identical(myris, myris2)

myris3 <- clean.iris(iris)

```

```{r}
# run a regression 
library(tidyverse)
head(starwars)

lm.results <- lm(get("mass") ~ height, data = starwars)
lm.summary <- summary(lm.results)
lm.summary$coefficients
# extract the estimate, p-value, and adjusted r-squared
results.table <- data.frame(estimate = lm.results$coefficients[2],
                            p.val = lm.summary$coefficients[2, "Pr(>|t|)"],
                            adj.r2 = lm.summary$adj.r.squared) 
results.table                            

# loop version: loop over genders
# NOTE: some genders only have one or two characters, so collapsing those into an "other" category
my.starwars <- starwars
my.starwars$gender2 <- ifelse(my.starwars$gender %in% c("male", "female"), my.starwars$gender, "other")
xtabs(~ gender + gender2, my.starwars)
all.genders <- unique(my.starwars$gender2)
results.table <- data.frame(gender = all.genders,
                            estimate = NA,
                            p.val = NA,
                            adj.r2 = NA)
for(this.gender in all.genders) {
  lm.results <- lm(mass ~ height, data = my.starwars[my.starwars$gender2 == this.gender, ])
  lm.summary <- summary(lm.results)
  lm.summary$coefficients
  # extract the estimate, p-value, and adjusted r-squared
  results.table[results.table$gender == this.gender, c("estimate", "p.val", "adj.r2")] <- 
    data.frame(estimate = lm.results$coefficients[2],
               p.val = lm.summary$coefficients[2, "Pr(>|t|)"],
               adj.r2 = lm.summary$adj.r.squared) 
}
results.table

# make a function to do it once
get.lm.results <- function(data, DV, predictor) {
  lm.results <- lm(get(DV) ~ get(predictor), data = data)
  lm.summary <- summary(lm.results)
  lm.summary$coefficients
  # extract the estimate, p-value, and adjusted r-squared
  results.table <- data.frame(estimate = lm.results$coefficients[2],
                              p.val = lm.summary$coefficients[2, "Pr(>|t|)"],
                              adj.r2 = lm.summary$adj.r.squared) 
  results.table               
}

get.lm.results(my.starwars, "mass", "height")

# dplyr do() version
all.results <- group_by(my.starwars, gender2) %>%
  do(get.lm.results(., "mass", "height"))
all.results

```


# More stuff on functions

## Environments
  - R can look "up" through environments, but not "down"
  - the body of a function is an environment, nested under the environment where it is called

```{r}

# remember that R can look "up" into environments
arg1 <- 40:45

bad.double.max <- function(x) { # not a good idea
  output <- max(arg1) * 2  
  output
}

y <- 1:10
bad.double.max(y)

rm(arg1)

bad.double.max(y)
y

double.max <- function(x) {
  max(x) * 2  # ok, because it's a value
}

bad.double.max2 <- function(x) {
  output <- max(x) * 2  # not returning a value
}

bad.double.max2(1:10)

#double.max <- function(x) { max(x) * 2 }
#double.max <- function(x) max(x) * 2 


double.max <- function(x) {
  output <- max(x) * 2  
  print(environment())
  print(objects())
  cat("\nThis is an awesome function\n")
  print(output)
  return(NULL)
}

x <- double.max(1:10)
x

y
double.max <- function(x) {
  output <- max(x) * 2
  y <- 6
  output
}

double.max(1:10)
y

evil.double.max <- function(x) {
  output <- max(x) * 2
  y <<- 6
  output
}

evil.double.max(5:70)
y

rm(y)
set.seed(42)
rnorm(3)
rnorm(5)
x <- evil.double.max(rnorm(20))
x
y

```


## Making functions available
  - in the notebook/script
  - `source()`
    - runs all code in another file

```{r}
# source("day9/anotherfunction.R")
#if your function is in a script, by itself, you can source()
#source runs all the code that's in that script file. 
```

  - package!
    - some package-making tutorials:
      - http://hilaryparker.com/2014/04/29/writing-an-r-package-from-scratch/
      - http://r-pkgs.had.co.nz/
      - https://support.rstudio.com/hc/en-us/articles/200486488-Developing-Packages-with-RStudio
      - http://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf
      - and lots more

## Debugging
  - run as a non-function
  - insert "test" code
  - use `browser()`, `debug()`, and `undebug()`
  
```{r}
my.analysis <- function() {
  library(dplyr)
  if(require(mice)) {
    print("run mice code")
  } else {
    print("run some alternative code")
  }   
}

my.analysis2 <- function() {
  library(dplyr)
  if(library(mice)) {  # throws an error
    print("run mice code")
  } else {
    print("run some alternative code")
  }   
}


mysleep <- sleep

my.pvals.v1 <- function(data) {
  test.results <- t.test(extra ~ group, data = data, paired = TRUE)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output
}

my.pvals.v1(mysleep)
mysleep2 <- mysleep[-c(3, 17), ]
my.pvals.v1(mysleep2)
mysleep3 <- mysleep
colnames(mysleep3) <- c("time.sleep", "condition", "subject")
my.pvals.v1(mysleep3)
```

```{r eval=FALSE}
my.pvals.v2 <- function(data, DV, factor) {
  test.results <- t.test(DV ~ factor, data = data, paired = paired)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output
}

my.pvals.v2(mysleep3, DV = "time.sleep", factor = "condition") # this will break!

```

### "fake function" debugging - essentially, making a test case

```{r}
my.pvals.v2(mysleep3, DV = "time.sleep", factor = "condition")

my.pvals.v2 <- function(data, DV, factor) {
  
  data <- mysleep3
  DV <- "time.sleep"
  factor <- "condition"
  
  test.results <- t.test(DV ~ factor, data = data)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output
  
  
  
}



```

### insert "print" statements

```{r}
my.pvals.v2(mysleep3, DV = "time.sleep", factor = "condition")

my.pvals.v2 <- function(data, DV, factor) {
  print(DV)
  test.results <- t.test(DV ~ factor, data = data)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output
  
  
  
}


```

### with debugging utilities
  - `browser()`
  - `debug()`, `undebug()`

```{r}
my.pvals.v2(mysleep3, DV = "time.sleep", factor = "condition")

my.pvals.v2 <- function(data, DV, factor) {
  #browser()
  test.results <- t.test(DV ~ factor, data = data)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output  
}

debug(my.pvals.v2)
undebug(my.pvals.v2)

my.pvals.v3 <- function(data, my.formula) {
  #browser()
  test.results <- t.test(my.formula, data = data)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output  
}

my.pvals.v3(mysleep3, time.sleep ~ condition)

my.pvals.v4 <- function(data, DV, factor) {
  formula.string <- paste(DV, "~", factor)
  my.formula <- as.formula(formula.string)
  test.results <- t.test(my.formula, data = data)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output  
}

my.pvals.v4(mysleep3, DV = "time.sleep", factor = "condition")


```

### dealing with user error

``` {r}
my.pvals.v4 <- function(data, DV, factor) {
  if(!is.data.frame(data)) {
    stop("Please supply a data frame, dear user") # can use warning() as well, does not throw error
  }
  formula.string <- paste(DV, "~", factor)
  my.formula <- as.formula(formula.string)
  test.results <- t.test(my.formula, data = data)
  pval <- test.results$p.value
  if (pval < .05) {
    output <- "p < .05, significant, thank god"
  } else {
    output <- paste("dammit, p is =", round(pval, 3))
  }
  output  
}

my.pvals.v4(as.matrix(mysleep3), DV = "time.sleep", factor = "condition")


```

# Extended example: power analysis

  - "power": likelihood of getting a target result
    - e.g. likelihood of "detecting" an effect at p < .05
  - process:
    1. implement data generation process
    2. simulate values using this process
    3. loop over many simulations, recording the "result" of each simulation
    4. summarize/analyze the simulated results
    
First: "type I" error, false positive rate

```{r}
# generating random (uncorrelated) data

# code up "one time" analysis

# create "results container"

# adapt "one time" code into a loop


# analyze results

```

Now: adapting to power analysis

```{r}
# generating correlated data with MASS package

# code up "one time" analysis

# create "results container"

# adapt "one time" code into a loop


# analyze results


```

Nesting loops: analyzing power under different parameters

```{r}


```
